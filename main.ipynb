{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.ultralytics.com/models/yolov8/#key-features-of-yolov8 for support and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/2 /home/capilab/Desktop/yolov8_test/test/pose/multiple.jpeg: 544x640 4 persons, 2265.2ms\n",
      "image 2/2 /home/capilab/Desktop/yolov8_test/test/pose/single.jpeg: 640x448 1 person, 1281.1ms\n",
      "Speed: 32.3ms preprocess, 1773.1ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mruns/pose/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "model = YOLO(\"yolov8n-pose.pt\") \n",
    "results = model(\"test/pose/*\", save=True) # specifiy path, in thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0., 0., 0., 0.])\n",
       "conf: tensor([0.9091, 0.9080, 0.9066, 0.8816])\n",
       "data: tensor([[6.8062e+02, 3.1498e+02, 9.0642e+02, 1.0669e+03, 9.0911e-01, 0.0000e+00],\n",
       "        [9.6266e+02, 3.1235e+02, 1.2800e+03, 1.0720e+03, 9.0797e-01, 0.0000e+00],\n",
       "        [3.7390e+02, 2.0085e+02, 6.2118e+02, 1.0620e+03, 9.0665e-01, 0.0000e+00],\n",
       "        [2.3157e+01, 2.5971e+02, 3.3576e+02, 1.0598e+03, 8.8158e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (1072, 1280)\n",
       "shape: torch.Size([4, 6])\n",
       "xywh: tensor([[ 793.5196,  690.9332,  225.8071,  751.8972],\n",
       "        [1121.3311,  692.1772,  317.3378,  759.6455],\n",
       "        [ 497.5392,  631.4420,  247.2780,  861.1785],\n",
       "        [ 179.4606,  659.7368,  312.6066,  800.0623]])\n",
       "xywhn: tensor([[0.6199, 0.6445, 0.1764, 0.7014],\n",
       "        [0.8760, 0.6457, 0.2479, 0.7086],\n",
       "        [0.3887, 0.5890, 0.1932, 0.8033],\n",
       "        [0.1402, 0.6154, 0.2442, 0.7463]])\n",
       "xyxy: tensor([[ 680.6160,  314.9846,  906.4232, 1066.8818],\n",
       "        [ 962.6622,  312.3545, 1280.0000, 1072.0000],\n",
       "        [ 373.9002,  200.8528,  621.1782, 1062.0312],\n",
       "        [  23.1573,  259.7057,  335.7639, 1059.7679]])\n",
       "xyxyn: tensor([[0.5317, 0.2938, 0.7081, 0.9952],\n",
       "        [0.7521, 0.2914, 1.0000, 1.0000],\n",
       "        [0.2921, 0.1874, 0.4853, 0.9907],\n",
       "        [0.0181, 0.2423, 0.2623, 0.9886]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes #result includeing box coordniate in image, confidents etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n-seg.pt\") \n",
    "results = model(\"test/classification/*\", save=True) # specifiy path, in thi\n",
    "print(f\"found {len(results)} in specific folder\")\n",
    "print(f\"first result {results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
